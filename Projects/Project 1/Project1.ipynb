{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ec94e2-5abc-4c04-b5bb-dea32df2eb50",
   "metadata": {},
   "source": [
    "# Implied-Vol Surface Completion (FC-NN + BS layer)\n",
    "## a lotta words to say that this project IS NOT COMPLETED YET!!!!\n",
    "\n",
    "\n",
    "**Goal (snapshot t_0):** Given a few option quotes at one timestamp, complete an **arbitrage-free** surface of prices/IV across strikes K and tenors T.  \n",
    "**Method:** Fully-connected MLP ‚Üí predicted IV ùúéÃÇ(K,T) ‚Üí **Black‚ÄìScholes** price layer ‚Üí fit to observed quotes.  \n",
    "**Stretch:** Small **PINN** term (BS-PDE residual + simple boundary/terminal penalties) as regularizer.  \n",
    "**Deliverables:** error/arb metrics, plots, ablation (baseline / +no-arb / +PINN / ensemble).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b60a509-2fab-444b-bdcb-92e7cf230b81",
   "metadata": {},
   "source": [
    "We will be building a black scholes model calculator in house and following this methodology:\n",
    " - Generate data using b-s model for pretraining\n",
    " - Utilize data from kaggle dataset(s) for fine-tuning\n",
    "\n",
    "\n",
    "maybe we can experiment with join curriculum, with 90% synthetic / 10% real and validate/test on real only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d5ec1-010c-4aba-887e-446cdc5e34b5",
   "metadata": {},
   "source": [
    "## Data generation using the Black-Scholes model\n",
    "Use b-s to generate \"snapshots\" of many quotes. Within each snapshot, pick 10-20 quotes as \"observed\", while treating the rest as targets for completion. This is fixed only once for fair comparison. We then use this phase to debug the model/tune rough ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d06239-f926-4442-8174-d9231e5653da",
   "metadata": {},
   "source": [
    "Black Scholes Formula (Call):\n",
    "$$ C = SN(d_1)-Ke^{rT}N(d_2) $$\n",
    "Where:\n",
    "- $C$: Price of the European call option\n",
    "- $S$: Current price of the underlying asset (spot)\n",
    "- $K$: Strike price of the option \n",
    "- $r$: Risk-free interest rate \n",
    "- $T$: Time to expiration (in years) \n",
    "- $\\sigma$: Volatility of the underlying asset's returns \n",
    "- $N(d_{1})$ and $N(d_{2})$: The cumulative standard normal distribution function, which gives the probability that a variable will be less than a certain value\n",
    "\n",
    "Put is different formula (to work on later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8002d91-7c20-491a-842e-1f2869129f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def bs_price(spot, strike, years, r, q, sigma, option=\"call\"):\n",
    "    T = np.asarray(years, dtype=float)\n",
    "    S = np.asarray(spot, dtype=float)\n",
    "    K = np.asarray(strike, dtype=float)\n",
    "    sig = np.asarray(sigma, dtype=float)\n",
    "\n",
    "    eps = 1e-12 # fix divide by zero error\n",
    "    \n",
    "    T = np.maximum(T, eps)\n",
    "    sig = np.maximum(sig, 1e-12)\n",
    "\n",
    "    d1 = (np.log(S / K) + (r - q + 0.5 * sig**2) * T) / (sig * np.sqrt(T))\n",
    "    d2 = d1 - sig * np.sqrt(T)\n",
    "\n",
    "    Nd1 = norm.cdf(d1)\n",
    "    Nd2 = norm.cdf(d2)\n",
    "\n",
    "    if option == \"call\":\n",
    "        return S * np.exp(-q * T) * Nd1 - K * np.exp(-r * T) * Nd2\n",
    "    else:  # put\n",
    "        return K * np.exp(-r * T) * norm.cdf(-d2) - S * np.exp(-q * T) * norm.cdf(-d1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e528e171-1703-4d79-9405-dcd291dc57d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_snapshot(snapshot_id, n_strikes=30, tenors_days=(7,14,30,60,90,180,365),\n",
    "                  smile=False, rng=None):\n",
    "    rng = np.random.default_rng(rng)\n",
    "\n",
    "    S0 = rng.uniform(50, 500)\n",
    "    r  = rng.uniform(0.00, 0.05)\n",
    "    q  = rng.uniform(0.00, 0.03)\n",
    "\n",
    "    m = rng.uniform(0.6, 1.4, size=n_strikes)  \n",
    "    K = np.sort(S0 * m) \n",
    "    T = np.array(tenors_days) / 365.0 \n",
    "\n",
    "    K_grid, T_grid = np.meshgrid(K, T, indexing=\"xy\")\n",
    "    S_grid = np.full_like(K_grid, S0)\n",
    "    r_grid = np.full_like(K_grid, r)\n",
    "    q_grid = np.full_like(K_grid, q)\n",
    "\n",
    "    # Volatility: constant or simple smile\n",
    "    if not smile:\n",
    "        sigma_snap = rng.uniform(0.10, 0.60)\n",
    "        sigma_grid = np.full_like(K_grid, sigma_snap)\n",
    "    else:\n",
    "        ell = np.log(S0 / K_grid)\n",
    "        a = rng.uniform(0.10, 0.50)\n",
    "        b = rng.uniform(-0.20, 0.20)\n",
    "        c = rng.uniform(0.00, 0.20)\n",
    "        d = rng.uniform(-0.05, 0.10)\n",
    "        sigma_grid = np.clip(a + b*ell + c*ell**2 + d*np.sqrt(T_grid), 0.05, 2.0)\n",
    "\n",
    "    P_mid = bs_price(S_grid, K_grid, T_grid, r_grid, q_grid, sigma_grid, option=\"call\")\n",
    "\n",
    "    noise = rng.normal(loc=0.0, scale=0.01*np.maximum(0.1, P_mid))\n",
    "    P_obs = np.clip(P_mid + noise, 0.0, None)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"snapshot_id\": snapshot_id,\n",
    "        \"S0\": S_grid.ravel(),\n",
    "        \"K\": K_grid.ravel(),\n",
    "        \"T\": T_grid.ravel(),\n",
    "        \"r\": r_grid.ravel(),\n",
    "        \"q\": q_grid.ravel(),\n",
    "        \"sigma_true\": sigma_grid.ravel(),\n",
    "        \"price_mid\": P_mid.ravel(),\n",
    "        \"price_obs\": P_obs.ravel(),\n",
    "    })\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e71e6790-c821-46d7-bdfe-0fa194e26738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(n_snapshots=2000, smile=False, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dfs = []\n",
    "    for sid in range(n_snapshots):\n",
    "        df = make_snapshot(sid, smile=smile, rng=rng)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d933ab-f559-45e2-a460-3a20c01bdd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_snapshots(n_snapshots, train=0.8, val=0.1, seed=7):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    ids = np.arange(n_snapshots)\n",
    "    rng.shuffle(ids)\n",
    "    n_train = int(train*n_snapshots)\n",
    "    n_val = int(val*n_snapshots)\n",
    "    return {\n",
    "        \"train\": ids[:n_train],\n",
    "        \"val\":   ids[n_train:n_train+n_val],\n",
    "        \"test\":  ids[n_train+n_val:]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4365eb-41c6-4ffe-8324-9b8f515b26b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_observed_mask(df, observed_per_snapshot=15, seed=99):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    mask = {}\n",
    "    for sid, df_s in df.groupby(\"snapshot_id\"):\n",
    "        idx = df_s.index.values\n",
    "        choose = min(observed_per_snapshot, len(idx))\n",
    "        obs_idx = rng.choice(idx, size=choose, replace=False)\n",
    "        mask[int(sid)] = np.sort(obs_idx)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72157f20-a67e-425c-8fa9-a3a9712b3b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Jupyter)",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
